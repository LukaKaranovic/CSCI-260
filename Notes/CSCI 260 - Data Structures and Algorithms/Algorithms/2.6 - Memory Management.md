## Issues in Memory Requests
- Fixed or varying length records are mixed together
- Different size records: small or large records
- Do we care more about response time efficiency or space usage efficiency?
- Does the system use explicit or implicit freeing techniques?

**The goals we want to achieve in memory management:**
1. Allocate blocks in required sizes.
2. Keep unused memory spaces as large as possible.
3. Combine memory spaces when they are freed.

**Cost Criteria:**
- Memory utilization (avoid unusable space)
- Memory usage overhead (for management structures)
- Allocation time efficiency (response to allocation requests quickly)
## Implicitly Freeing Memory Space (Garbage Collection)
1. **Reference counts:**  
    The reference count of a memory space is incremented for each new reference to the space, and is decremented if a reference is overwritten, or if the referring object is recycled. 
    
    If a reference count falls to zero, then the object is no longer required and can be recycled.  
    
    The main problems with simple reference counting:
    - The reference count field usually has to have limited size, and the system therefore breaks down if the number of possible references to an object is unbounded.
    - Reference counting involves an operation on every modification of a pointer, which increases code size, increases demand for memory bandwidth, decreases locality of references, and can be a serious performance penalty (especially in multi-threaded environments where reference count updates require synchronization).
    - Every object needs to be slightly larger in order to store the reference count.
    - If any objects are part of a cyclic data structure, then they will always have a non-zero reference count, and hence won't be reclaimed when they are dead.
    - ![[Pasted image 20241208201527.png]]
2. **Mark and sweep:**
    The mark phase follows reference chains to mark all reachable objects; the sweep phase performs a sequential (address-order) pass over memory to recycle all unmarked objects.  
    
    The mark phase can be done as a depth-first search to identify all live objects (objects in use). And the sweep phase put unreachable (dead) objects to free list.
3. **Mark and compress:**
    Mark all reachable objects, then compress the marked objects.
    
	The compression phase typically performs a number of sequential passes over memory to move marked (live) objects and update references.  
	
    As a result of compression, all the marked objects are moved into a single contiguous block of memory (or a small number of such blocks); the memory left unused after compression is recycled.  
    
    This method can eliminate internal fragmentation, thus make large free blocks available for more efficient allocation mechanisms. However, it is quite expensive to copy large blocks used by live objects.
## Explicitly Freeing Memory Space
Two operations explicitly called by applications:
1. Allocate (new/malloc/calloc)
2. Free (delete/free)
## Utilization of Memory Space
Utilization of memory space can't be perfect - it's an NP-complete problem.
The heuristics commonly used for allocation include:
1. **Best Fit:** Allocate to the smallest block that satisfies the request.
2. **Worst Fit:** Always allocate from the largest block (so that a bigger chunk may be left for later use hopefully).
3. **First Fit:** Allocate to the first block that satisfies the request (it is usually as good as best fit).
4. Allocate to the most recently freed block that satisfies the request.
## Example Memory Management Methods
1. **The Boundary-Tag method:** 
    * The free blocks are doubly and circularly linked. The worst case allocation cost is to search the entire list to find a fit. The freeing cost is constant.
2. **Buddy System:**  
    * There is an array of free lists, one for each allowable block size. Allocation rounds up the requested size to an allowable size and allocates from the corresponding free list. If the free list is empty, a larger block is selected and split into two equal sized buddies. 
    * A block may only be combined with its buddy, and this is only possible if the buddy has not been split into smaller blocks.  
    * The advantage of buddy system is that the buddy of a block being freed can be quickly found by a simple address computation.  
    * The disadvantage of buddy system is that the restricted set of block sizes leads to high internal fragmentation, as does the limited ability to combine the freed blocks.